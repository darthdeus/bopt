C:\dev\Miniconda3\python.exe C:/dev/master-thesis-code/optimize_cmdargs.py
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.5997052659448596', '--epsilon=0.13627467890909423', '--gamma=0.8286403949283767', '--episodes=300']
[2018-11-19 15:00:40,483] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -953.9
Episode 30, mean 100-episode return -882.3333333333334
Episode 40, mean 100-episode return -856.15
Episode 50, mean 100-episode return -805.08
Episode 60, mean 100-episode return -776.6
Episode 70, mean 100-episode return -737.5
Episode 80, mean 100-episode return -726.975
Episode 90, mean 100-episode return -727.9777777777778
Episode 100, mean 100-episode return -728.66
Episode 110, mean 100-episode return -684.31
Episode 120, mean 100-episode return -649.29
Episode 130, mean 100-episode return -625.06
Episode 140, mean 100-episode return -593.0
Episode 150, mean 100-episode return -593.0
Episode 160, mean 100-episode return -591.69
Episode 170, mean 100-episode return -601.67
Episode 180, mean 100-episode return -580.17
Episode 190, mean 100-episode return -538.7
Episode 200, mean 100-episode return -518.21
Episode 210, mean 100-episode return -494.99
Episode 220, mean 100-episode return -466.78
Episode 230, mean 100-episode return -448.58
Episode 240, mean 100-episode return -461.81
Episode 250, mean 100-episode return -452.43
Episode 260, mean 100-episode return -428.45
Episode 270, mean 100-episode return -417.14
Episode 280, mean 100-episode return -399.76
Episode 290, mean 100-episode return -417.86
Episode 300, mean 100-episode return -405.5
Episode 310, mean 100-episode return -400.27
Episode 320, mean 100-episode return -397.56
Episode 330, mean 100-episode return -391.79
Episode 340, mean 100-episode return -357.14
Episode 350, mean 100-episode return -331.69
Episode 360, mean 100-episode return -317.47
Episode 370, mean 100-episode return -292.56
Episode 380, mean 100-episode return -289.72
Episode 390, mean 100-episode return -264.58
Episode 400, mean 100-episode return -248.69
Finished with: 0

***
b'The mean 100-episode return after evaluation -246.93\r\n'
*** Reward: -246.93
Found optimal params [ 1.         15.71368822]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.05', '--epsilon=0.8', '--gamma=0.99', '--episodes=300']
[2018-11-19 15:00:47,757] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -1000.0
Episode 30, mean 100-episode return -1000.0
Episode 40, mean 100-episode return -1000.0
Episode 50, mean 100-episode return -1000.0
Episode 60, mean 100-episode return -1000.0
Episode 70, mean 100-episode return -1000.0
Episode 80, mean 100-episode return -986.975
Episode 90, mean 100-episode return -984.8444444444444
Episode 100, mean 100-episode return -986.36
Episode 110, mean 100-episode return -985.08
Episode 120, mean 100-episode return -972.27
Episode 130, mean 100-episode return -956.4
Episode 140, mean 100-episode return -947.56
Episode 150, mean 100-episode return -936.52
Episode 160, mean 100-episode return -914.22
Episode 170, mean 100-episode return -898.17
Episode 180, mean 100-episode return -883.48
Episode 190, mean 100-episode return -861.4
Episode 200, mean 100-episode return -832.76
Episode 210, mean 100-episode return -794.53
Episode 220, mean 100-episode return -772.89
Episode 230, mean 100-episode return -758.0
Episode 240, mean 100-episode return -721.76
Episode 250, mean 100-episode return -683.06
Episode 260, mean 100-episode return -655.94
Episode 270, mean 100-episode return -625.71
Episode 280, mean 100-episode return -598.95
Episode 290, mean 100-episode return -582.05
Episode 300, mean 100-episode return -560.82
Episode 310, mean 100-episode return -535.02
Episode 320, mean 100-episode return -500.85
Episode 330, mean 100-episode return -465.28
Episode 340, mean 100-episode return -445.15
Episode 350, mean 100-episode return -432.47
Episode 360, mean 100-episode return -414.6
Episode 370, mean 100-episode return -389.64
Episode 380, mean 100-episode return -373.53
Episode 390, mean 100-episode return -349.72
Episode 400, mean 100-episode return -335.46
Finished with: 0

***
b'The mean 100-episode return after evaluation -333.18\r\n'
*** Reward: -333.18
Found optimal params [ 2.95165749 10.02598635]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=1.0', '--epsilon=0.03', '--gamma=0.8', '--episodes=300']
[2018-11-19 15:00:57,750] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -1000.0
Episode 30, mean 100-episode return -946.4
Episode 40, mean 100-episode return -959.8
Episode 50, mean 100-episode return -967.84
Episode 60, mean 100-episode return -961.7666666666667
Episode 70, mean 100-episode return -961.4714285714285
Episode 80, mean 100-episode return -956.6125
Episode 90, mean 100-episode return -940.8444444444444
Episode 100, mean 100-episode return -918.44
Episode 110, mean 100-episode return -898.66
Episode 120, mean 100-episode return -883.67
Episode 130, mean 100-episode return -889.2
Episode 140, mean 100-episode return -878.52
Episode 150, mean 100-episode return -851.76
Episode 160, mean 100-episode return -826.35
Episode 170, mean 100-episode return -830.17
Episode 180, mean 100-episode return -837.91
Episode 190, mean 100-episode return -845.91
Episode 200, mean 100-episode return -861.06
Episode 210, mean 100-episode return -872.19
Episode 220, mean 100-episode return -853.74
Episode 230, mean 100-episode return -845.0
Episode 240, mean 100-episode return -836.19
Episode 250, mean 100-episode return -835.3
Episode 260, mean 100-episode return -863.42
Episode 270, mean 100-episode return -863.63
Episode 280, mean 100-episode return -863.63
Episode 290, mean 100-episode return -874.16
Episode 300, mean 100-episode return -887.33
Episode 310, mean 100-episode return -895.98
Episode 320, mean 100-episode return -929.42
Episode 330, mean 100-episode return -948.71
Episode 340, mean 100-episode return -968.2
Episode 350, mean 100-episode return -995.85
Episode 360, mean 100-episode return -1000.0
Episode 370, mean 100-episode return -1000.0
Episode 380, mean 100-episode return -1000.0
Episode 390, mean 100-episode return -1000.0
Episode 400, mean 100-episode return -1000.0
Finished with: 0

***
b'The mean 100-episode return after evaluation -1000.0\r\n'
*** Reward: -1000.0
Found optimal params [0.29494347 5.06952752]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.21814268250168548', '--epsilon=0.03599741532734616', '--gamma=0.8084332521546055', '--episodes=300']
[2018-11-19 15:01:10,657] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -1000.0
Episode 30, mean 100-episode return -995.2
Episode 40, mean 100-episode return -961.65
Episode 50, mean 100-episode return -901.6
Episode 60, mean 100-episode return -853.1833333333333
Episode 70, mean 100-episode return -820.5857142857143
Episode 80, mean 100-episode return -783.4625
Episode 90, mean 100-episode return -761.1111111111111
Episode 100, mean 100-episode return -770.12
Episode 110, mean 100-episode return -714.77
Episode 120, mean 100-episode return -663.72
Episode 130, mean 100-episode return -643.81
Episode 140, mean 100-episode return -612.72
Episode 150, mean 100-episode return -591.0
Episode 160, mean 100-episode return -573.03
Episode 170, mean 100-episode return -559.51
Episode 180, mean 100-episode return -547.85
Episode 190, mean 100-episode return -532.76
Episode 200, mean 100-episode return -480.38
Episode 210, mean 100-episode return -486.25
Episode 220, mean 100-episode return -470.09
Episode 230, mean 100-episode return -421.62
Episode 240, mean 100-episode return -400.23
Episode 250, mean 100-episode return -389.73
Episode 260, mean 100-episode return -383.61
Episode 270, mean 100-episode return -363.59
Episode 280, mean 100-episode return -357.88
Episode 290, mean 100-episode return -353.09
Episode 300, mean 100-episode return -355.61
Episode 310, mean 100-episode return -397.83
Episode 320, mean 100-episode return -465.04
Episode 330, mean 100-episode return -534.86
Episode 340, mean 100-episode return -601.24
Episode 350, mean 100-episode return -667.32
Episode 360, mean 100-episode return -730.3
Episode 370, mean 100-episode return -801.34
Episode 380, mean 100-episode return -866.35
Episode 390, mean 100-episode return -928.0
Episode 400, mean 100-episode return -992.74
Finished with: 0

***
b'The mean 100-episode return after evaluation -1000.0\r\n'
*** Reward: -1000.0
Found optimal params [1.27461841e-03 3.74390461e+00]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.45195023933608486', '--epsilon=0.7197236261635861', '--gamma=0.8831482870870027', '--episodes=300']
[2018-11-19 15:01:19,262] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -998.05
Episode 30, mean 100-episode return -982.0333333333333
Episode 40, mean 100-episode return -969.9
Episode 50, mean 100-episode return -946.22
Episode 60, mean 100-episode return -938.5166666666667
Episode 70, mean 100-episode return -928.3571428571429
Episode 80, mean 100-episode return -913.5625
Episode 90, mean 100-episode return -910.5444444444445
Episode 100, mean 100-episode return -897.42
Episode 110, mean 100-episode return -884.79
Episode 120, mean 100-episode return -846.48
Episode 130, mean 100-episode return -814.87
Episode 140, mean 100-episode return -785.27
Episode 150, mean 100-episode return -765.65
Episode 160, mean 100-episode return -741.89
Episode 170, mean 100-episode return -735.49
Episode 180, mean 100-episode return -733.3
Episode 190, mean 100-episode return -694.43
Episode 200, mean 100-episode return -671.12
Episode 210, mean 100-episode return -630.14
Episode 220, mean 100-episode return -625.42
Episode 230, mean 100-episode return -622.07
Episode 240, mean 100-episode return -591.91
Episode 250, mean 100-episode return -563.27
Episode 260, mean 100-episode return -541.94
Episode 270, mean 100-episode return -496.69
Episode 280, mean 100-episode return -445.96
Episode 290, mean 100-episode return -429.04
Episode 300, mean 100-episode return -411.62
Episode 310, mean 100-episode return -461.21
Episode 320, mean 100-episode return -504.63
Episode 330, mean 100-episode return -544.59
Episode 340, mean 100-episode return -611.0
Episode 350, mean 100-episode return -674.11
Episode 360, mean 100-episode return -729.2
Episode 370, mean 100-episode return -794.11
Episode 380, mean 100-episode return -866.03
Episode 390, mean 100-episode return -933.18
Episode 400, mean 100-episode return -995.98
Finished with: 0

***
b'The mean 100-episode return after evaluation -1000.0\r\n'
*** Reward: -1000.0
Found optimal params [1.00000000e-05 3.04295579e+00]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.7105427083550585', '--epsilon=0.24979315302466285', '--gamma=0.985773027557324', '--episodes=300']
[2018-11-19 15:01:29,070] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -1000.0
Episode 30, mean 100-episode return -944.0
Episode 40, mean 100-episode return -941.375
Episode 50, mean 100-episode return -906.82
Episode 60, mean 100-episode return -866.1
Episode 70, mean 100-episode return -856.1714285714286
Episode 80, mean 100-episode return -824.7875
Episode 90, mean 100-episode return -804.4555555555555
Episode 100, mean 100-episode return -789.53
Episode 110, mean 100-episode return -750.12
Episode 120, mean 100-episode return -722.2
Episode 130, mean 100-episode return -701.92
Episode 140, mean 100-episode return -681.62
Episode 150, mean 100-episode return -679.8
Episode 160, mean 100-episode return -677.28
Episode 170, mean 100-episode return -669.27
Episode 180, mean 100-episode return -684.28
Episode 190, mean 100-episode return -679.69
Episode 200, mean 100-episode return -673.71
Episode 210, mean 100-episode return -670.82
Episode 220, mean 100-episode return -646.91
Episode 230, mean 100-episode return -630.06
Episode 240, mean 100-episode return -628.27
Episode 250, mean 100-episode return -616.08
Episode 260, mean 100-episode return -598.73
Episode 270, mean 100-episode return -573.54
Episode 280, mean 100-episode return -542.83
Episode 290, mean 100-episode return -529.62
Episode 300, mean 100-episode return -517.22
Episode 310, mean 100-episode return -486.91
Episode 320, mean 100-episode return -465.93
Episode 330, mean 100-episode return -447.48
Episode 340, mean 100-episode return -403.05
Episode 350, mean 100-episode return -367.04
Episode 360, mean 100-episode return -346.43
Episode 370, mean 100-episode return -326.39
Episode 380, mean 100-episode return -306.69
Episode 390, mean 100-episode return -285.1
Episode 400, mean 100-episode return -263.66
Finished with: 0

***
b'The mean 100-episode return after evaluation -262.61\r\n'
*** Reward: -262.61
Found optimal params [1.00000000e-05 2.56528732e+00]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.5240679098210048', '--epsilon=0.7637140166779282', '--gamma=0.922637425434061', '--episodes=300']
[2018-11-19 15:01:37,555] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -1000.0
Episode 30, mean 100-episode return -999.8
Episode 40, mean 100-episode return -982.2
Episode 50, mean 100-episode return -971.78
Episode 60, mean 100-episode return -974.0666666666667
Episode 70, mean 100-episode return -972.0285714285715
Episode 80, mean 100-episode return -953.975
Episode 90, mean 100-episode return -935.8666666666667
Episode 100, mean 100-episode return -918.22
Episode 110, mean 100-episode return -900.19
Episode 120, mean 100-episode return -888.41
Episode 130, mean 100-episode return -871.49
Episode 140, mean 100-episode return -849.42
Episode 150, mean 100-episode return -832.77
Episode 160, mean 100-episode return -807.6
Episode 170, mean 100-episode return -762.27
Episode 180, mean 100-episode return -733.37
Episode 190, mean 100-episode return -709.17
Episode 200, mean 100-episode return -705.67
Episode 210, mean 100-episode return -718.19
Episode 220, mean 100-episode return -686.39
Episode 230, mean 100-episode return -651.07
Episode 240, mean 100-episode return -626.96
Episode 250, mean 100-episode return -603.84
Episode 260, mean 100-episode return -583.22
Episode 270, mean 100-episode return -570.36
Episode 280, mean 100-episode return -548.08
Episode 290, mean 100-episode return -531.03
Episode 300, mean 100-episode return -485.48
Episode 310, mean 100-episode return -413.85
Episode 320, mean 100-episode return -379.64
Episode 330, mean 100-episode return -354.21
Episode 340, mean 100-episode return -328.52
Episode 350, mean 100-episode return -298.37
Episode 360, mean 100-episode return -267.19
Episode 370, mean 100-episode return -251.02
Episode 380, mean 100-episode return -242.78
Episode 390, mean 100-episode return -227.5
Episode 400, mean 100-episode return -222.82
Finished with: 0

***
b'The mean 100-episode return after evaluation -223.0\r\n'
*** Reward: -223.0
Found optimal params [0.06890047 2.28403825]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.5837081561204635', '--epsilon=0.8', '--gamma=0.9552943582681487', '--episodes=300']
[2018-11-19 15:01:46,691] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -1000.0
Episode 30, mean 100-episode return -997.2666666666667
Episode 40, mean 100-episode return -997.95
Episode 50, mean 100-episode return -997.8
Episode 60, mean 100-episode return -998.1666666666666
Episode 70, mean 100-episode return -990.3428571428572
Episode 80, mean 100-episode return -987.625
Episode 90, mean 100-episode return -989.0
Episode 100, mean 100-episode return -980.89
Episode 110, mean 100-episode return -959.05
Episode 120, mean 100-episode return -942.04
Episode 130, mean 100-episode return -922.06
Episode 140, mean 100-episode return -898.33
Episode 150, mean 100-episode return -879.31
Episode 160, mean 100-episode return -856.87
Episode 170, mean 100-episode return -844.01
Episode 180, mean 100-episode return -823.81
Episode 190, mean 100-episode return -780.49
Episode 200, mean 100-episode return -758.36
Episode 210, mean 100-episode return -751.8
Episode 220, mean 100-episode return -726.65
Episode 230, mean 100-episode return -708.25
Episode 240, mean 100-episode return -676.63
Episode 250, mean 100-episode return -649.11
Episode 260, mean 100-episode return -636.9
Episode 270, mean 100-episode return -600.67
Episode 280, mean 100-episode return -558.89
Episode 290, mean 100-episode return -561.7
Episode 300, mean 100-episode return -526.86
Episode 310, mean 100-episode return -482.04
Episode 320, mean 100-episode return -451.18
Episode 330, mean 100-episode return -417.14
Episode 340, mean 100-episode return -399.58
Episode 350, mean 100-episode return -372.91
Episode 360, mean 100-episode return -334.16
Episode 370, mean 100-episode return -315.89
Episode 380, mean 100-episode return -306.72
Episode 390, mean 100-episode return -273.78
Episode 400, mean 100-episode return -266.54
Finished with: 0

***
b'The mean 100-episode return after evaluation -266.68\r\n'
*** Reward: -266.68
Found optimal params [0.06865017 2.11673553]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=1.0', '--epsilon=0.5557858083425024', '--gamma=0.8', '--episodes=300']
[2018-11-19 15:01:56,408] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -1000.0
Episode 30, mean 100-episode return -1000.0
Episode 40, mean 100-episode return -1000.0
Episode 50, mean 100-episode return -1000.0
Episode 60, mean 100-episode return -1000.0
Episode 70, mean 100-episode return -1000.0
Episode 80, mean 100-episode return -999.95
Episode 90, mean 100-episode return -999.9555555555555
Episode 100, mean 100-episode return -999.96
Episode 110, mean 100-episode return -999.96
Episode 120, mean 100-episode return -999.96
Episode 130, mean 100-episode return -999.96
Episode 140, mean 100-episode return -999.96
Episode 150, mean 100-episode return -999.96
Episode 160, mean 100-episode return -994.7
Episode 170, mean 100-episode return -989.91
Episode 180, mean 100-episode return -978.13
Episode 190, mean 100-episode return -978.13
Episode 200, mean 100-episode return -978.13
Episode 210, mean 100-episode return -976.68
Episode 220, mean 100-episode return -967.88
Episode 230, mean 100-episode return -967.88
Episode 240, mean 100-episode return -967.88
Episode 250, mean 100-episode return -967.88
Episode 260, mean 100-episode return -963.2
Episode 270, mean 100-episode return -936.08
Episode 280, mean 100-episode return -934.92
Episode 290, mean 100-episode return -932.63
Episode 300, mean 100-episode return -932.63
Episode 310, mean 100-episode return -934.08
Episode 320, mean 100-episode return -942.88
Episode 330, mean 100-episode return -942.88
Episode 340, mean 100-episode return -942.88
Episode 350, mean 100-episode return -942.88
Episode 360, mean 100-episode return -952.82
Episode 370, mean 100-episode return -984.73
Episode 380, mean 100-episode return -997.71
Episode 390, mean 100-episode return -1000.0
Episode 400, mean 100-episode return -1000.0
Finished with: 0

***
b'The mean 100-episode return after evaluation -1000.0\r\n'
*** Reward: -1000.0
Found optimal params [0.07359548 1.99305309]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.05', '--epsilon=0.4313498115782077', '--gamma=0.8', '--episodes=300']
[2018-11-19 15:02:10,299] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -1000.0
Episode 30, mean 100-episode return -1000.0
Episode 40, mean 100-episode return -1000.0
Episode 50, mean 100-episode return -1000.0
Episode 60, mean 100-episode return -1000.0
Episode 70, mean 100-episode return -1000.0
Episode 80, mean 100-episode return -996.475
Episode 90, mean 100-episode return -994.2555555555556
Episode 100, mean 100-episode return -982.31
Episode 110, mean 100-episode return -974.5
Episode 120, mean 100-episode return -969.06
Episode 130, mean 100-episode return -960.55
Episode 140, mean 100-episode return -947.09
Episode 150, mean 100-episode return -928.41
Episode 160, mean 100-episode return -907.13
Episode 170, mean 100-episode return -883.97
Episode 180, mean 100-episode return -866.04
Episode 190, mean 100-episode return -848.04
Episode 200, mean 100-episode return -828.13
Episode 210, mean 100-episode return -803.2
Episode 220, mean 100-episode return -785.86
Episode 230, mean 100-episode return -760.98
Episode 240, mean 100-episode return -733.83
Episode 250, mean 100-episode return -710.02
Episode 260, mean 100-episode return -686.14
Episode 270, mean 100-episode return -660.3
Episode 280, mean 100-episode return -626.76
Episode 290, mean 100-episode return -595.38
Episode 300, mean 100-episode return -572.04
Episode 310, mean 100-episode return -542.9
Episode 320, mean 100-episode return -496.34
Episode 330, mean 100-episode return -456.45
Episode 340, mean 100-episode return -432.13
Episode 350, mean 100-episode return -411.94
Episode 360, mean 100-episode return -400.97
Episode 370, mean 100-episode return -381.77
Episode 380, mean 100-episode return -385.65
Episode 390, mean 100-episode return -379.4
Episode 400, mean 100-episode return -376.88
Finished with: 0

***
b'The mean 100-episode return after evaluation -374.07\r\n'
*** Reward: -374.07
Found optimal params [0.0708443  1.85714564]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.35425768059545615', '--epsilon=0.3582681396576799', '--gamma=0.99', '--episodes=300']
[2018-11-19 15:02:20,771] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -1000.0
Episode 30, mean 100-episode return -976.2333333333333
Episode 40, mean 100-episode return -916.95
Episode 50, mean 100-episode return -880.12
Episode 60, mean 100-episode return -874.7333333333333
Episode 70, mean 100-episode return -875.2714285714286
Episode 80, mean 100-episode return -848.0375
Episode 90, mean 100-episode return -831.6
Episode 100, mean 100-episode return -798.08
Episode 110, mean 100-episode return -746.02
Episode 120, mean 100-episode return -695.7
Episode 130, mean 100-episode return -642.89
Episode 140, mean 100-episode return -612.34
Episode 150, mean 100-episode return -581.2
Episode 160, mean 100-episode return -538.89
Episode 170, mean 100-episode return -493.8
Episode 180, mean 100-episode return -466.41
Episode 190, mean 100-episode return -435.13
Episode 200, mean 100-episode return -416.58
Episode 210, mean 100-episode return -410.82
Episode 220, mean 100-episode return -409.1
Episode 230, mean 100-episode return -411.91
Episode 240, mean 100-episode return -407.46
Episode 250, mean 100-episode return -412.28
Episode 260, mean 100-episode return -441.48
Episode 270, mean 100-episode return -448.06
Episode 280, mean 100-episode return -449.74
Episode 290, mean 100-episode return -449.38
Episode 300, mean 100-episode return -456.81
Episode 310, mean 100-episode return -456.81
Episode 320, mean 100-episode return -440.33
Episode 330, mean 100-episode return -432.42
Episode 340, mean 100-episode return -418.28
Episode 350, mean 100-episode return -414.25
Episode 360, mean 100-episode return -369.41
Episode 370, mean 100-episode return -350.81
Episode 380, mean 100-episode return -344.53
Episode 390, mean 100-episode return -340.36
Episode 400, mean 100-episode return -340.29
Finished with: 0

***
b'The mean 100-episode return after evaluation -338.74\r\n'
*** Reward: -338.74
Found optimal params [0.06850726 1.75256378]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.670864311964425', '--epsilon=0.49213597263433223', '--gamma=0.8', '--episodes=300']
[2018-11-19 15:02:28,627] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -1000.0
Episode 30, mean 100-episode return -999.6
Episode 40, mean 100-episode return -985.4
Episode 50, mean 100-episode return -960.46
Episode 60, mean 100-episode return -925.85
Episode 70, mean 100-episode return -913.8857142857142
Episode 80, mean 100-episode return -895.85
Episode 90, mean 100-episode return -893.6111111111111
Episode 100, mean 100-episode return -896.67
Episode 110, mean 100-episode return -870.25
Episode 120, mean 100-episode return -857.6
Episode 130, mean 100-episode return -827.15
Episode 140, mean 100-episode return -817.31
Episode 150, mean 100-episode return -808.9
Episode 160, mean 100-episode return -794.93
Episode 170, mean 100-episode return -794.27
Episode 180, mean 100-episode return -774.13
Episode 190, mean 100-episode return -753.7
Episode 200, mean 100-episode return -752.74
Episode 210, mean 100-episode return -751.88
Episode 220, mean 100-episode return -740.11
Episode 230, mean 100-episode return -741.66
Episode 240, mean 100-episode return -712.73
Episode 250, mean 100-episode return -692.7
Episode 260, mean 100-episode return -685.07
Episode 270, mean 100-episode return -678.72
Episode 280, mean 100-episode return -675.08
Episode 290, mean 100-episode return -655.29
Episode 300, mean 100-episode return -603.64
Episode 310, mean 100-episode return -623.6
Episode 320, mean 100-episode return -648.02
Episode 330, mean 100-episode return -677.04
Episode 340, mean 100-episode return -721.53
Episode 350, mean 100-episode return -763.9
Episode 360, mean 100-episode return -810.22
Episode 370, mean 100-episode return -833.02
Episode 380, mean 100-episode return -879.84
Episode 390, mean 100-episode return -932.49
Episode 400, mean 100-episode return -992.68
Finished with: 0

***
b'The mean 100-episode return after evaluation -1000.0\r\n'
*** Reward: -1000.0
Found optimal params [0.07224646 1.69270836]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=1.0', '--epsilon=0.8', '--gamma=0.99', '--episodes=300']
[2018-11-19 15:02:39,750] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -1000.0
Episode 30, mean 100-episode return -1000.0
Episode 40, mean 100-episode return -1000.0
Episode 50, mean 100-episode return -1000.0
Episode 60, mean 100-episode return -996.35
Episode 70, mean 100-episode return -996.8714285714286
Episode 80, mean 100-episode return -997.2625
Episode 90, mean 100-episode return -997.5666666666667
Episode 100, mean 100-episode return -997.81
Episode 110, mean 100-episode return -995.56
Episode 120, mean 100-episode return -995.56
Episode 130, mean 100-episode return -995.56
Episode 140, mean 100-episode return -995.56
Episode 150, mean 100-episode return -995.56
Episode 160, mean 100-episode return -997.75
Episode 170, mean 100-episode return -997.75
Episode 180, mean 100-episode return -997.75
Episode 190, mean 100-episode return -997.75
Episode 200, mean 100-episode return -997.75
Episode 210, mean 100-episode return -985.65
Episode 220, mean 100-episode return -966.64
Episode 230, mean 100-episode return -963.45
Episode 240, mean 100-episode return -961.79
Episode 250, mean 100-episode return -959.41
Episode 260, mean 100-episode return -959.41
Episode 270, mean 100-episode return -957.03
Episode 280, mean 100-episode return -957.03
Episode 290, mean 100-episode return -946.05
Episode 300, mean 100-episode return -934.85
Episode 310, mean 100-episode return -916.61
Episode 320, mean 100-episode return -898.34
Episode 330, mean 100-episode return -851.7
Episode 340, mean 100-episode return -807.19
Episode 350, mean 100-episode return -776.88
Episode 360, mean 100-episode return -731.07
Episode 370, mean 100-episode return -690.97
Episode 380, mean 100-episode return -643.55
Episode 390, mean 100-episode return -601.0
Episode 400, mean 100-episode return -572.02
Finished with: 0

***
b'The mean 100-episode return after evaluation -574.86\r\n'
*** Reward: -574.86
Found optimal params [0.07145894 1.62689997]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=1.0', '--epsilon=0.29605494210926103', '--gamma=0.99', '--episodes=300']
[2018-11-19 15:02:52,355] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -987.7
Episode 30, mean 100-episode return -987.7
Episode 40, mean 100-episode return -986.6
Episode 50, mean 100-episode return -984.48
Episode 60, mean 100-episode return -987.0666666666667
Episode 70, mean 100-episode return -987.4571428571429
Episode 80, mean 100-episode return -985.3625
Episode 90, mean 100-episode return -983.5888888888888
Episode 100, mean 100-episode return -982.27
Episode 110, mean 100-episode return -972.26
Episode 120, mean 100-episode return -966.14
Episode 130, mean 100-episode return -958.83
Episode 140, mean 100-episode return -955.39
Episode 150, mean 100-episode return -937.21
Episode 160, mean 100-episode return -937.21
Episode 170, mean 100-episode return -938.23
Episode 180, mean 100-episode return -928.28
Episode 190, mean 100-episode return -931.34
Episode 200, mean 100-episode return -930.93
Episode 210, mean 100-episode return -940.94
Episode 220, mean 100-episode return -934.88
Episode 230, mean 100-episode return -936.34
Episode 240, mean 100-episode return -920.29
Episode 250, mean 100-episode return -935.06
Episode 260, mean 100-episode return -930.64
Episode 270, mean 100-episode return -928.28
Episode 280, mean 100-episode return -927.15
Episode 290, mean 100-episode return -920.83
Episode 300, mean 100-episode return -922.06
Episode 310, mean 100-episode return -922.06
Episode 320, mean 100-episode return -936.7
Episode 330, mean 100-episode return -943.78
Episode 340, mean 100-episode return -964.94
Episode 350, mean 100-episode return -970.75
Episode 360, mean 100-episode return -975.17
Episode 370, mean 100-episode return -977.53
Episode 380, mean 100-episode return -991.54
Episode 390, mean 100-episode return -997.86
Episode 400, mean 100-episode return -1000.0
Finished with: 0

***
b'The mean 100-episode return after evaluation -1000.0\r\n'
*** Reward: -1000.0
Found optimal params [1.00000000e-05 1.54506837e+00]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.6609873065522517', '--epsilon=0.707001529811415', '--gamma=0.9218261083137306', '--episodes=300']
[2018-11-19 15:03:05,446] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -1000.0
Episode 30, mean 100-episode return -994.7333333333333
Episode 40, mean 100-episode return -976.475
Episode 50, mean 100-episode return -963.58
Episode 60, mean 100-episode return -953.9166666666666
Episode 70, mean 100-episode return -944.6571428571428
Episode 80, mean 100-episode return -944.425
Episode 90, mean 100-episode return -945.3
Episode 100, mean 100-episode return -944.51
Episode 110, mean 100-episode return -944.21
Episode 120, mean 100-episode return -937.54
Episode 130, mean 100-episode return -935.03
Episode 140, mean 100-episode return -925.1
Episode 150, mean 100-episode return -922.47
Episode 160, mean 100-episode return -924.77
Episode 170, mean 100-episode return -891.02
Episode 180, mean 100-episode return -854.61
Episode 190, mean 100-episode return -823.22
Episode 200, mean 100-episode return -792.72
Episode 210, mean 100-episode return -766.59
Episode 220, mean 100-episode return -739.78
Episode 230, mean 100-episode return -708.01
Episode 240, mean 100-episode return -699.33
Episode 250, mean 100-episode return -680.06
Episode 260, mean 100-episode return -633.05
Episode 270, mean 100-episode return -625.72
Episode 280, mean 100-episode return -610.36
Episode 290, mean 100-episode return -586.41
Episode 300, mean 100-episode return -559.42
Episode 310, mean 100-episode return -535.42
Episode 320, mean 100-episode return -507.17
Episode 330, mean 100-episode return -484.24
Episode 340, mean 100-episode return -440.67
Episode 350, mean 100-episode return -420.36
Episode 360, mean 100-episode return -408.09
Episode 370, mean 100-episode return -396.32
Episode 380, mean 100-episode return -393.83
Episode 390, mean 100-episode return -392.87
Episode 400, mean 100-episode return -399.61
Finished with: 0

***
b'The mean 100-episode return after evaluation -398.39\r\n'
*** Reward: -398.39
Found optimal params [0.08686641 1.56380956]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.1839980683415076', '--epsilon=0.5708582761001116', '--gamma=0.99', '--episodes=300']
[2018-11-19 15:03:15,485] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -999.5
Episode 30, mean 100-episode return -999.6666666666666
Episode 40, mean 100-episode return -998.725
Episode 50, mean 100-episode return -969.06
Episode 60, mean 100-episode return -932.2833333333333
Episode 70, mean 100-episode return -904.1285714285714
Episode 80, mean 100-episode return -888.075
Episode 90, mean 100-episode return -872.9444444444445
Episode 100, mean 100-episode return -843.32
Episode 110, mean 100-episode return -796.97
Episode 120, mean 100-episode return -750.08
Episode 130, mean 100-episode return -721.88
Episode 140, mean 100-episode return -667.23
Episode 150, mean 100-episode return -633.06
Episode 160, mean 100-episode return -604.29
Episode 170, mean 100-episode return -580.82
Episode 180, mean 100-episode return -551.58
Episode 190, mean 100-episode return -520.25
Episode 200, mean 100-episode return -503.0
Episode 210, mean 100-episode return -496.64
Episode 220, mean 100-episode return -482.99
Episode 230, mean 100-episode return -479.75
Episode 240, mean 100-episode return -487.76
Episode 250, mean 100-episode return -472.41
Episode 260, mean 100-episode return -461.69
Episode 270, mean 100-episode return -452.64
Episode 280, mean 100-episode return -469.03
Episode 290, mean 100-episode return -472.58
Episode 300, mean 100-episode return -469.02
Episode 310, mean 100-episode return -475.18
Episode 320, mean 100-episode return -477.19
Episode 330, mean 100-episode return -452.15
Episode 340, mean 100-episode return -434.59
Episode 350, mean 100-episode return -448.8
Episode 360, mean 100-episode return -450.09
Episode 370, mean 100-episode return -451.02
Episode 380, mean 100-episode return -425.5
Episode 390, mean 100-episode return -420.4
Episode 400, mean 100-episode return -424.43
Finished with: 0

***
b'The mean 100-episode return after evaluation -422.77\r\n'
*** Reward: -422.77
Found optimal params [0.08807292 1.52332859]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.05', '--epsilon=0.215539697886746', '--gamma=0.99', '--episodes=300']
[2018-11-19 15:03:23,898] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -1000.0
Episode 30, mean 100-episode return -1000.0
Episode 40, mean 100-episode return -1000.0
Episode 50, mean 100-episode return -1000.0
Episode 60, mean 100-episode return -996.9666666666667
Episode 70, mean 100-episode return -997.4
Episode 80, mean 100-episode return -995.325
Episode 90, mean 100-episode return -994.4444444444445
Episode 100, mean 100-episode return -989.46
Episode 110, mean 100-episode return -975.14
Episode 120, mean 100-episode return -956.18
Episode 130, mean 100-episode return -940.38
Episode 140, mean 100-episode return -935.24
Episode 150, mean 100-episode return -909.11
Episode 160, mean 100-episode return -898.38
Episode 170, mean 100-episode return -869.29
Episode 180, mean 100-episode return -837.57
Episode 190, mean 100-episode return -807.66
Episode 200, mean 100-episode return -794.49
Episode 210, mean 100-episode return -778.25
Episode 220, mean 100-episode return -776.02
Episode 230, mean 100-episode return -754.06
Episode 240, mean 100-episode return -717.19
Episode 250, mean 100-episode return -698.34
Episode 260, mean 100-episode return -668.96
Episode 270, mean 100-episode return -668.1
Episode 280, mean 100-episode return -664.1
Episode 290, mean 100-episode return -661.35
Episode 300, mean 100-episode return -632.81
Episode 310, mean 100-episode return -600.38
Episode 320, mean 100-episode return -554.83
Episode 330, mean 100-episode return -527.18
Episode 340, mean 100-episode return -503.54
Episode 350, mean 100-episode return -482.99
Episode 360, mean 100-episode return -459.7
Episode 370, mean 100-episode return -422.94
Episode 380, mean 100-episode return -394.5
Episode 390, mean 100-episode return -361.31
Episode 400, mean 100-episode return -343.14
Finished with: 0

***
b'The mean 100-episode return after evaluation -341.08\r\n'
*** Reward: -341.08
Found optimal params [1.00000000e-05 1.43078964e+00]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.8179290833431875', '--epsilon=0.47741171834885143', '--gamma=0.9460331003138006', '--episodes=300']
[2018-11-19 15:03:34,210] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -965.85
Episode 30, mean 100-episode return -963.1
Episode 40, mean 100-episode return -970.875
Episode 50, mean 100-episode return -963.0
Episode 60, mean 100-episode return -957.4833333333333
Episode 70, mean 100-episode return -951.9
Episode 80, mean 100-episode return -950.95
Episode 90, mean 100-episode return -952.2555555555556
Episode 100, mean 100-episode return -938.23
Episode 110, mean 100-episode return -933.93
Episode 120, mean 100-episode return -937.08
Episode 130, mean 100-episode return -914.27
Episode 140, mean 100-episode return -905.85
Episode 150, mean 100-episode return -875.35
Episode 160, mean 100-episode return -849.7
Episode 170, mean 100-episode return -847.61
Episode 180, mean 100-episode return -828.98
Episode 190, mean 100-episode return -809.45
Episode 200, mean 100-episode return -785.88
Episode 210, mean 100-episode return -772.61
Episode 220, mean 100-episode return -725.58
Episode 230, mean 100-episode return -723.1
Episode 240, mean 100-episode return -709.92
Episode 250, mean 100-episode return -714.2
Episode 260, mean 100-episode return -697.42
Episode 270, mean 100-episode return -653.02
Episode 280, mean 100-episode return -637.06
Episode 290, mean 100-episode return -645.73
Episode 300, mean 100-episode return -631.6
Episode 310, mean 100-episode return -568.39
Episode 320, mean 100-episode return -537.55
Episode 330, mean 100-episode return -486.18
Episode 340, mean 100-episode return -428.43
Episode 350, mean 100-episode return -384.68
Episode 360, mean 100-episode return -354.16
Episode 370, mean 100-episode return -327.98
Episode 380, mean 100-episode return -287.87
Episode 390, mean 100-episode return -222.35
Episode 400, mean 100-episode return -198.72
Finished with: 0

***
b'The mean 100-episode return after evaluation -199.56\r\n'
*** Reward: -199.56
Found optimal params [0.09018108 1.45650859]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.4552560145221858', '--epsilon=0.03', '--gamma=0.99', '--episodes=300']
[2018-11-19 15:03:44,122] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -926.0
Episode 30, mean 100-episode return -857.2
Episode 40, mean 100-episode return -840.1
Episode 50, mean 100-episode return -801.76
Episode 60, mean 100-episode return -804.4833333333333
Episode 70, mean 100-episode return -804.7142857142857
Episode 80, mean 100-episode return -770.1
Episode 90, mean 100-episode return -731.3555555555556
Episode 100, mean 100-episode return -705.8
Episode 110, mean 100-episode return -653.47
Episode 120, mean 100-episode return -612.96
Episode 130, mean 100-episode return -579.15
Episode 140, mean 100-episode return -536.2
Episode 150, mean 100-episode return -510.16
Episode 160, mean 100-episode return -460.26
Episode 170, mean 100-episode return -410.25
Episode 180, mean 100-episode return -391.04
Episode 190, mean 100-episode return -390.94
Episode 200, mean 100-episode return -394.47
Episode 210, mean 100-episode return -401.29
Episode 220, mean 100-episode return -414.4
Episode 230, mean 100-episode return -428.31
Episode 240, mean 100-episode return -426.38
Episode 250, mean 100-episode return -422.54
Episode 260, mean 100-episode return -420.74
Episode 270, mean 100-episode return -418.83
Episode 280, mean 100-episode return -415.31
Episode 290, mean 100-episode return -406.8
Episode 300, mean 100-episode return -386.12
Episode 310, mean 100-episode return -350.73
Episode 320, mean 100-episode return -313.54
Episode 330, mean 100-episode return -279.86
Episode 340, mean 100-episode return -265.49
Episode 350, mean 100-episode return -248.56
Episode 360, mean 100-episode return -237.03
Episode 370, mean 100-episode return -228.1
Episode 380, mean 100-episode return -216.12
Episode 390, mean 100-episode return -201.9
Episode 400, mean 100-episode return -189.5
Finished with: 0

***
b'The mean 100-episode return after evaluation -189.13\r\n'
*** Reward: -189.13
Found optimal params [0.0865301  1.42145381]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.18079325724581488', '--epsilon=0.8', '--gamma=0.8', '--episodes=300']
[2018-11-19 15:03:50,805] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -1000.0
Episode 30, mean 100-episode return -1000.0
Episode 40, mean 100-episode return -989.025
Episode 50, mean 100-episode return -975.06
Episode 60, mean 100-episode return -967.9666666666667
Episode 70, mean 100-episode return -962.2285714285714
Episode 80, mean 100-episode return -948.4375
Episode 90, mean 100-episode return -941.4333333333333
Episode 100, mean 100-episode return -916.76
Episode 110, mean 100-episode return -887.02
Episode 120, mean 100-episode return -849.52
Episode 130, mean 100-episode return -823.16
Episode 140, mean 100-episode return -794.23
Episode 150, mean 100-episode return -771.69
Episode 160, mean 100-episode return -742.72
Episode 170, mean 100-episode return -713.45
Episode 180, mean 100-episode return -671.68
Episode 190, mean 100-episode return -628.37
Episode 200, mean 100-episode return -598.56
Episode 210, mean 100-episode return -569.4
Episode 220, mean 100-episode return -548.67
Episode 230, mean 100-episode return -523.66
Episode 240, mean 100-episode return -499.83
Episode 250, mean 100-episode return -466.11
Episode 260, mean 100-episode return -438.96
Episode 270, mean 100-episode return -413.26
Episode 280, mean 100-episode return -418.1
Episode 290, mean 100-episode return -417.19
Episode 300, mean 100-episode return -406.3
Episode 310, mean 100-episode return -389.88
Episode 320, mean 100-episode return -370.5
Episode 330, mean 100-episode return -344.94
Episode 340, mean 100-episode return -325.45
Episode 350, mean 100-episode return -314.9
Episode 360, mean 100-episode return -300.96
Episode 370, mean 100-episode return -286.0
Episode 380, mean 100-episode return -261.94
Episode 390, mean 100-episode return -241.64
Episode 400, mean 100-episode return -237.45
Finished with: 0

***
b'The mean 100-episode return after evaluation -236.64\r\n'
*** Reward: -236.64
Found optimal params [0.08688893 1.3965862 ]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.40882862687230864', '--epsilon=0.27094186994063', '--gamma=0.8', '--episodes=300']
[2018-11-19 15:03:58,925] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -954.45
Episode 30, mean 100-episode return -915.7
Episode 40, mean 100-episode return -879.725
Episode 50, mean 100-episode return -842.28
Episode 60, mean 100-episode return -846.5166666666667
Episode 70, mean 100-episode return -809.9142857142857
Episode 80, mean 100-episode return -790.9
Episode 90, mean 100-episode return -750.8555555555556
Episode 100, mean 100-episode return -719.23
Episode 110, mean 100-episode return -671.46
Episode 120, mean 100-episode return -621.69
Episode 130, mean 100-episode return -588.37
Episode 140, mean 100-episode return -562.28
Episode 150, mean 100-episode return -538.51
Episode 160, mean 100-episode return -494.39
Episode 170, mean 100-episode return -475.46
Episode 180, mean 100-episode return -445.29
Episode 190, mean 100-episode return -462.63
Episode 200, mean 100-episode return -453.87
Episode 210, mean 100-episode return -459.56
Episode 220, mean 100-episode return -464.36
Episode 230, mean 100-episode return -458.66
Episode 240, mean 100-episode return -446.48
Episode 250, mean 100-episode return -449.46
Episode 260, mean 100-episode return -436.47
Episode 270, mean 100-episode return -421.03
Episode 280, mean 100-episode return -415.14
Episode 290, mean 100-episode return -383.4
Episode 300, mean 100-episode return -372.71
Episode 310, mean 100-episode return -344.5
Episode 320, mean 100-episode return -326.07
Episode 330, mean 100-episode return -309.35
Episode 340, mean 100-episode return -295.21
Episode 350, mean 100-episode return -274.67
Episode 360, mean 100-episode return -271.94
Episode 370, mean 100-episode return -274.34
Episode 380, mean 100-episode return -272.52
Episode 390, mean 100-episode return -270.46
Episode 400, mean 100-episode return -275.2
Finished with: 0

***
b'The mean 100-episode return after evaluation -276.21\r\n'
*** Reward: -276.21
Found optimal params [0.10909391 1.40913051]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.05', '--epsilon=0.8', '--gamma=0.8', '--episodes=300']
[2018-11-19 15:04:05,811] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -1000.0
Episode 30, mean 100-episode return -1000.0
Episode 40, mean 100-episode return -1000.0
Episode 50, mean 100-episode return -1000.0
Episode 60, mean 100-episode return -1000.0
Episode 70, mean 100-episode return -1000.0
Episode 80, mean 100-episode return -1000.0
Episode 90, mean 100-episode return -992.2555555555556
Episode 100, mean 100-episode return -989.51
Episode 110, mean 100-episode return -981.42
Episode 120, mean 100-episode return -973.84
Episode 130, mean 100-episode return -962.97
Episode 140, mean 100-episode return -952.35
Episode 150, mean 100-episode return -939.48
Episode 160, mean 100-episode return -922.38
Episode 170, mean 100-episode return -919.53
Episode 180, mean 100-episode return -903.67
Episode 190, mean 100-episode return -893.93
Episode 200, mean 100-episode return -855.93
Episode 210, mean 100-episode return -838.62
Episode 220, mean 100-episode return -811.65
Episode 230, mean 100-episode return -788.3
Episode 240, mean 100-episode return -757.92
Episode 250, mean 100-episode return -726.36
Episode 260, mean 100-episode return -692.08
Episode 270, mean 100-episode return -661.51
Episode 280, mean 100-episode return -641.71
Episode 290, mean 100-episode return -626.63
Episode 300, mean 100-episode return -635.55
Episode 310, mean 100-episode return -655.28
Episode 320, mean 100-episode return -689.83
Episode 330, mean 100-episode return -724.05
Episode 340, mean 100-episode return -765.05
Episode 350, mean 100-episode return -809.48
Episode 360, mean 100-episode return -860.86
Episode 370, mean 100-episode return -894.28
Episode 380, mean 100-episode return -929.94
Episode 390, mean 100-episode return -961.73
Episode 400, mean 100-episode return -994.33
Finished with: 0

***
b'The mean 100-episode return after evaluation -1000.0\r\n'
*** Reward: -1000.0
Found optimal params [0.10171872 1.38506941]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.7593116111191173', '--epsilon=0.03', '--gamma=0.99', '--episodes=300']
[2018-11-19 15:04:17,606] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -987.85
Episode 30, mean 100-episode return -962.3
Episode 40, mean 100-episode return -871.525
Episode 50, mean 100-episode return -813.56
Episode 60, mean 100-episode return -789.6666666666666
Episode 70, mean 100-episode return -803.6571428571428
Episode 80, mean 100-episode return -768.2375
Episode 90, mean 100-episode return -726.2555555555556
Episode 100, mean 100-episode return -688.6
Episode 110, mean 100-episode return -632.25
Episode 120, mean 100-episode return -578.74
Episode 130, mean 100-episode return -555.22
Episode 140, mean 100-episode return -543.25
Episode 150, mean 100-episode return -546.04
Episode 160, mean 100-episode return -543.79
Episode 170, mean 100-episode return -523.4
Episode 180, mean 100-episode return -519.3
Episode 190, mean 100-episode return -521.89
Episode 200, mean 100-episode return -523.28
Episode 210, mean 100-episode return -516.66
Episode 220, mean 100-episode return -508.17
Episode 230, mean 100-episode return -485.33
Episode 240, mean 100-episode return -488.9
Episode 250, mean 100-episode return -465.64
Episode 260, mean 100-episode return -446.32
Episode 270, mean 100-episode return -415.45
Episode 280, mean 100-episode return -401.68
Episode 290, mean 100-episode return -400.8
Episode 300, mean 100-episode return -417.38
Episode 310, mean 100-episode return -473.32
Episode 320, mean 100-episode return -537.75
Episode 330, mean 100-episode return -592.99
Episode 340, mean 100-episode return -641.47
Episode 350, mean 100-episode return -703.77
Episode 360, mean 100-episode return -758.32
Episode 370, mean 100-episode return -820.82
Episode 380, mean 100-episode return -886.66
Episode 390, mean 100-episode return -945.91
Episode 400, mean 100-episode return -992.97
Finished with: 0

***
b'The mean 100-episode return after evaluation -1000.0\r\n'
*** Reward: -1000.0
Found optimal params [0.11414241 1.39177835]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.40449629025501976', '--epsilon=0.11416711296097566', '--gamma=0.9885664395787578', '--episodes=300']
[2018-11-19 15:04:26,580] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -1000.0
Episode 30, mean 100-episode return -975.6
Episode 40, mean 100-episode return -930.675
Episode 50, mean 100-episode return -890.92
Episode 60, mean 100-episode return -831.6333333333333
Episode 70, mean 100-episode return -785.4714285714285
Episode 80, mean 100-episode return -749.475
Episode 90, mean 100-episode return -720.4222222222222
Episode 100, mean 100-episode return -688.33
Episode 110, mean 100-episode return -638.92
Episode 120, mean 100-episode return -600.7
Episode 130, mean 100-episode return -565.64
Episode 140, mean 100-episode return -523.59
Episode 150, mean 100-episode return -488.86
Episode 160, mean 100-episode return -484.18
Episode 170, mean 100-episode return -480.96
Episode 180, mean 100-episode return -491.91
Episode 190, mean 100-episode return -506.1
Episode 200, mean 100-episode return -517.37
Episode 210, mean 100-episode return -509.61
Episode 220, mean 100-episode return -485.88
Episode 230, mean 100-episode return -469.07
Episode 240, mean 100-episode return -460.7
Episode 250, mean 100-episode return -453.29
Episode 260, mean 100-episode return -451.2
Episode 270, mean 100-episode return -437.62
Episode 280, mean 100-episode return -407.33
Episode 290, mean 100-episode return -382.57
Episode 300, mean 100-episode return -362.94
Episode 310, mean 100-episode return -413.22
Episode 320, mean 100-episode return -475.17
Episode 330, mean 100-episode return -534.36
Episode 340, mean 100-episode return -605.19
Episode 350, mean 100-episode return -674.14
Episode 360, mean 100-episode return -727.39
Episode 370, mean 100-episode return -793.34
Episode 380, mean 100-episode return -862.93
Episode 390, mean 100-episode return -924.7
Episode 400, mean 100-episode return -993.11
Finished with: 0

***
b'The mean 100-episode return after evaluation -1000.0\r\n'
*** Reward: -1000.0
Found optimal params [0.11323753 1.39157669]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.1940147810009762', '--epsilon=0.3247447482263529', '--gamma=0.8062254267981452', '--episodes=300']
[2018-11-19 15:04:35,145] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -1000.0
Episode 30, mean 100-episode return -976.6666666666666
Episode 40, mean 100-episode return -962.65
Episode 50, mean 100-episode return -940.52
Episode 60, mean 100-episode return -895.9666666666667
Episode 70, mean 100-episode return -873.7714285714286
Episode 80, mean 100-episode return -862.2
Episode 90, mean 100-episode return -832.3555555555556
Episode 100, mean 100-episode return -800.72
Episode 110, mean 100-episode return -765.34
Episode 120, mean 100-episode return -718.92
Episode 130, mean 100-episode return -670.71
Episode 140, mean 100-episode return -630.77
Episode 150, mean 100-episode return -597.33
Episode 160, mean 100-episode return -571.03
Episode 170, mean 100-episode return -535.32
Episode 180, mean 100-episode return -499.8
Episode 190, mean 100-episode return -482.33
Episode 200, mean 100-episode return -476.44
Episode 210, mean 100-episode return -457.28
Episode 220, mean 100-episode return -449.07
Episode 230, mean 100-episode return -443.56
Episode 240, mean 100-episode return -435.05
Episode 250, mean 100-episode return -412.85
Episode 260, mean 100-episode return -419.53
Episode 270, mean 100-episode return -416.7
Episode 280, mean 100-episode return -409.1
Episode 290, mean 100-episode return -398.37
Episode 300, mean 100-episode return -384.12
Episode 310, mean 100-episode return -381.55
Episode 320, mean 100-episode return -369.64
Episode 330, mean 100-episode return -367.51
Episode 340, mean 100-episode return -349.4
Episode 350, mean 100-episode return -364.08
Episode 360, mean 100-episode return -342.82
Episode 370, mean 100-episode return -339.07
Episode 380, mean 100-episode return -336.09
Episode 390, mean 100-episode return -338.77
Episode 400, mean 100-episode return -343.76
Finished with: 0

***
b'The mean 100-episode return after evaluation -343.44\r\n'
*** Reward: -343.44
Found optimal params [0.11642962 1.38384645]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.7008448552827221', '--epsilon=0.7195369268390636', '--gamma=0.8322041552863388', '--episodes=300']
[2018-11-19 15:04:42,950] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -998.25
Episode 30, mean 100-episode return -990.1
Episode 40, mean 100-episode return -988.375
Episode 50, mean 100-episode return -989.86
Episode 60, mean 100-episode return -984.9333333333333
Episode 70, mean 100-episode return -985.7428571428571
Episode 80, mean 100-episode return -982.0625
Episode 90, mean 100-episode return -977.8333333333334
Episode 100, mean 100-episode return -976.42
Episode 110, mean 100-episode return -968.02
Episode 120, mean 100-episode return -950.8
Episode 130, mean 100-episode return -937.27
Episode 140, mean 100-episode return -933.81
Episode 150, mean 100-episode return -923.48
Episode 160, mean 100-episode return -898.03
Episode 170, mean 100-episode return -892.43
Episode 180, mean 100-episode return -882.54
Episode 190, mean 100-episode return -874.33
Episode 200, mean 100-episode return -852.93
Episode 210, mean 100-episode return -827.66
Episode 220, mean 100-episode return -814.73
Episode 230, mean 100-episode return -812.94
Episode 240, mean 100-episode return -782.94
Episode 250, mean 100-episode return -761.9
Episode 260, mean 100-episode return -753.72
Episode 270, mean 100-episode return -728.45
Episode 280, mean 100-episode return -707.05
Episode 290, mean 100-episode return -680.12
Episode 300, mean 100-episode return -639.18
Episode 310, mean 100-episode return -603.41
Episode 320, mean 100-episode return -560.23
Episode 330, mean 100-episode return -504.42
Episode 340, mean 100-episode return -465.81
Episode 350, mean 100-episode return -422.59
Episode 360, mean 100-episode return -385.03
Episode 370, mean 100-episode return -343.51
Episode 380, mean 100-episode return -303.4
Episode 390, mean 100-episode return -269.67
Episode 400, mean 100-episode return -261.11
Finished with: 0

***
b'The mean 100-episode return after evaluation -256.68\r\n'
*** Reward: -256.68
Found optimal params [0.11868216 1.39050708]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.32724945235816694', '--epsilon=0.26475231768612906', '--gamma=0.8569358090993588', '--episodes=300']
[2018-11-19 15:04:53,239] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -995.6
Episode 30, mean 100-episode return -987.6666666666666
Episode 40, mean 100-episode return -908.875
Episode 50, mean 100-episode return -876.1
Episode 60, mean 100-episode return -835.6666666666666
Episode 70, mean 100-episode return -787.1
Episode 80, mean 100-episode return -751.375
Episode 90, mean 100-episode return -722.5
Episode 100, mean 100-episode return -701.9
Episode 110, mean 100-episode return -670.59
Episode 120, mean 100-episode return -614.2
Episode 130, mean 100-episode return -561.71
Episode 140, mean 100-episode return -539.46
Episode 150, mean 100-episode return -528.29
Episode 160, mean 100-episode return -525.3
Episode 170, mean 100-episode return -516.58
Episode 180, mean 100-episode return -506.78
Episode 190, mean 100-episode return -497.95
Episode 200, mean 100-episode return -495.75
Episode 210, mean 100-episode return -489.75
Episode 220, mean 100-episode return -485.71
Episode 230, mean 100-episode return -485.37
Episode 240, mean 100-episode return -482.3
Episode 250, mean 100-episode return -453.58
Episode 260, mean 100-episode return -428.07
Episode 270, mean 100-episode return -418.93
Episode 280, mean 100-episode return -407.5
Episode 290, mean 100-episode return -408.92
Episode 300, mean 100-episode return -384.62
Episode 310, mean 100-episode return -346.78
Episode 320, mean 100-episode return -332.17
Episode 330, mean 100-episode return -311.32
Episode 340, mean 100-episode return -292.44
Episode 350, mean 100-episode return -282.34
Episode 360, mean 100-episode return -271.35
Episode 370, mean 100-episode return -262.69
Episode 380, mean 100-episode return -259.24
Episode 390, mean 100-episode return -241.67
Episode 400, mean 100-episode return -241.05
Finished with: 0

***
b'The mean 100-episode return after evaluation -240.43\r\n'
*** Reward: -240.43
Found optimal params [0.28368098 2.84771408]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.2877433341735537', '--epsilon=0.8', '--gamma=0.99', '--episodes=300']
[2018-11-19 15:05:00,355] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -1000.0
Episode 30, mean 100-episode return -996.9666666666667
Episode 40, mean 100-episode return -997.725
Episode 50, mean 100-episode return -972.34
Episode 60, mean 100-episode return -973.2166666666667
Episode 70, mean 100-episode return -960.0714285714286
Episode 80, mean 100-episode return -932.6125
Episode 90, mean 100-episode return -902.1666666666666
Episode 100, mean 100-episode return -888.65
Episode 110, mean 100-episode return -860.89
Episode 120, mean 100-episode return -827.22
Episode 130, mean 100-episode return -793.24
Episode 140, mean 100-episode return -743.33
Episode 150, mean 100-episode return -724.31
Episode 160, mean 100-episode return -675.95
Episode 170, mean 100-episode return -643.25
Episode 180, mean 100-episode return -627.01
Episode 190, mean 100-episode return -610.14
Episode 200, mean 100-episode return -588.22
Episode 210, mean 100-episode return -559.17
Episode 220, mean 100-episode return -530.05
Episode 230, mean 100-episode return -512.83
Episode 240, mean 100-episode return -504.44
Episode 250, mean 100-episode return -469.08
Episode 260, mean 100-episode return -451.98
Episode 270, mean 100-episode return -430.14
Episode 280, mean 100-episode return -402.4
Episode 290, mean 100-episode return -396.14
Episode 300, mean 100-episode return -400.12
Episode 310, mean 100-episode return -395.85
Episode 320, mean 100-episode return -416.89
Episode 330, mean 100-episode return -424.73
Episode 340, mean 100-episode return -420.89
Episode 350, mean 100-episode return -431.18
Episode 360, mean 100-episode return -444.25
Episode 370, mean 100-episode return -461.98
Episode 380, mean 100-episode return -475.39
Episode 390, mean 100-episode return -478.57
Episode 400, mean 100-episode return -471.24
Finished with: 0

***
b'The mean 100-episode return after evaluation -471.98\r\n'
*** Reward: -471.98
Found optimal params [0.1200289  1.39052112]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.32006676975637943', '--epsilon=0.32402901338258977', '--gamma=0.8186956026033222', '--episodes=300']
[2018-11-19 15:05:08,782] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -1000.0
Episode 30, mean 100-episode return -996.9333333333333
Episode 40, mean 100-episode return -932.825
Episode 50, mean 100-episode return -898.48
Episode 60, mean 100-episode return -866.2333333333333
Episode 70, mean 100-episode return -843.0142857142857
Episode 80, mean 100-episode return -801.775
Episode 90, mean 100-episode return -772.8111111111111
Episode 100, mean 100-episode return -740.8
Episode 110, mean 100-episode return -683.59
Episode 120, mean 100-episode return -627.34
Episode 130, mean 100-episode return -576.44
Episode 140, mean 100-episode return -572.54
Episode 150, mean 100-episode return -539.71
Episode 160, mean 100-episode return -506.34
Episode 170, mean 100-episode return -480.56
Episode 180, mean 100-episode return -459.14
Episode 190, mean 100-episode return -445.86
Episode 200, mean 100-episode return -434.92
Episode 210, mean 100-episode return -423.69
Episode 220, mean 100-episode return -417.83
Episode 230, mean 100-episode return -413.05
Episode 240, mean 100-episode return -412.0
Episode 250, mean 100-episode return -414.0
Episode 260, mean 100-episode return -420.4
Episode 270, mean 100-episode return -413.91
Episode 280, mean 100-episode return -410.54
Episode 290, mean 100-episode return -408.7
Episode 300, mean 100-episode return -403.95
Episode 310, mean 100-episode return -413.1
Episode 320, mean 100-episode return -409.72
Episode 330, mean 100-episode return -401.36
Episode 340, mean 100-episode return -358.21
Episode 350, mean 100-episode return -355.62
Episode 360, mean 100-episode return -337.52
Episode 370, mean 100-episode return -330.45
Episode 380, mean 100-episode return -333.96
Episode 390, mean 100-episode return -328.7
Episode 400, mean 100-episode return -334.77
Finished with: 0

***
b'The mean 100-episode return after evaluation -334.83\r\n'
*** Reward: -334.83
Found optimal params [0.11992247 1.41196353]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.13573364730453424', '--epsilon=0.6139441439487047', '--gamma=0.9816133268107505', '--episodes=300']
[2018-11-19 15:05:16,036] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -1000.0
Episode 30, mean 100-episode return -1000.0
Episode 40, mean 100-episode return -978.325
Episode 50, mean 100-episode return -964.04
Episode 60, mean 100-episode return -958.7833333333333
Episode 70, mean 100-episode return -941.6
Episode 80, mean 100-episode return -915.05
Episode 90, mean 100-episode return -898.6888888888889
Episode 100, mean 100-episode return -884.06
Episode 110, mean 100-episode return -859.57
Episode 120, mean 100-episode return -839.18
Episode 130, mean 100-episode return -788.83
Episode 140, mean 100-episode return -748.73
Episode 150, mean 100-episode return -712.47
Episode 160, mean 100-episode return -673.99
Episode 170, mean 100-episode return -633.44
Episode 180, mean 100-episode return -607.92
Episode 190, mean 100-episode return -577.14
Episode 200, mean 100-episode return -544.93
Episode 210, mean 100-episode return -510.0
Episode 220, mean 100-episode return -477.85
Episode 230, mean 100-episode return -470.29
Episode 240, mean 100-episode return -466.88
Episode 250, mean 100-episode return -457.23
Episode 260, mean 100-episode return -449.73
Episode 270, mean 100-episode return -440.06
Episode 280, mean 100-episode return -430.35
Episode 290, mean 100-episode return -429.57
Episode 300, mean 100-episode return -429.92
Episode 310, mean 100-episode return -412.73
Episode 320, mean 100-episode return -389.78
Episode 330, mean 100-episode return -373.9
Episode 340, mean 100-episode return -348.75
Episode 350, mean 100-episode return -330.59
Episode 360, mean 100-episode return -305.41
Episode 370, mean 100-episode return -296.44
Episode 380, mean 100-episode return -283.51
Episode 390, mean 100-episode return -262.91
Episode 400, mean 100-episode return -244.32
Finished with: 0

***
b'The mean 100-episode return after evaluation -242.93\r\n'
*** Reward: -242.93
max_x [0.45525601 0.03       0.99      ] max max -189.13




****************************
OptimizationResult(best_x=[0.45525601 0.03       0.99      ], best_y=-189.13)

Process finished with exit code 0
