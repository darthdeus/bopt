C:\dev\Miniconda3\python.exe C:/dev/master-thesis-code/optimize_cmdargs.py
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.8747105470625397', '--epsilon=0.4468805918600406', '--gamma=0.8817356964910568']
[2018-11-19 14:52:07,948] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -1000.0
Episode 30, mean 100-episode return -979.1333333333333
Episode 40, mean 100-episode return -971.9
Episode 50, mean 100-episode return -962.96
Episode 60, mean 100-episode return -954.85
Episode 70, mean 100-episode return -939.8142857142857
Episode 80, mean 100-episode return -925.9125
Episode 90, mean 100-episode return -895.2777777777778
Episode 100, mean 100-episode return -860.83
Episode 110, mean 100-episode return -856.27
Episode 120, mean 100-episode return -856.27
Episode 130, mean 100-episode return -848.92
Episode 140, mean 100-episode return -853.9
Episode 150, mean 100-episode return -861.18
Episode 160, mean 100-episode return -869.75
Episode 170, mean 100-episode return -864.37
Episode 180, mean 100-episode return -881.51
Episode 190, mean 100-episode return -916.49
Episode 200, mean 100-episode return -961.41
Finished with: 0

***
b'The mean 100-episode return after evaluation -965.97\r\n'
*** Reward: -965.97
Found optimal params [ 1.         31.07989673]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=2.0', '--epsilon=0.03', '--gamma=0.99']
[2018-11-19 14:52:13,882] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -1000.0
Episode 30, mean 100-episode return -1000.0
Episode 40, mean 100-episode return -1000.0
Episode 50, mean 100-episode return -1000.0
Episode 60, mean 100-episode return -990.6833333333333
Episode 70, mean 100-episode return -992.0142857142857
Episode 80, mean 100-episode return -986.8625
Episode 90, mean 100-episode return -988.3222222222222
Episode 100, mean 100-episode return -986.91
Episode 110, mean 100-episode return -986.91
Episode 120, mean 100-episode return -986.91
Episode 130, mean 100-episode return -986.91
Episode 140, mean 100-episode return -986.91
Episode 150, mean 100-episode return -986.91
Episode 160, mean 100-episode return -992.5
Episode 170, mean 100-episode return -992.5
Episode 180, mean 100-episode return -997.42
Episode 190, mean 100-episode return -997.42
Episode 200, mean 100-episode return -1000.0
Finished with: 0

***
b'The mean 100-episode return after evaluation -1000.0\r\n'
*** Reward: -1000.0
Found optimal params [35.11899369 30.51171236]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.05', '--epsilon=0.8', '--gamma=0.8']
[2018-11-19 14:52:20,341] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -1000.0
Episode 30, mean 100-episode return -1000.0
Episode 40, mean 100-episode return -1000.0
Episode 50, mean 100-episode return -1000.0
Episode 60, mean 100-episode return -1000.0
Episode 70, mean 100-episode return -1000.0
Episode 80, mean 100-episode return -1000.0
Episode 90, mean 100-episode return -992.0888888888888
Episode 100, mean 100-episode return -989.68
Episode 110, mean 100-episode return -989.68
Episode 120, mean 100-episode return -989.68
Episode 130, mean 100-episode return -989.68
Episode 140, mean 100-episode return -989.68
Episode 150, mean 100-episode return -989.68
Episode 160, mean 100-episode return -989.68
Episode 170, mean 100-episode return -989.68
Episode 180, mean 100-episode return -989.68
Episode 190, mean 100-episode return -996.8
Episode 200, mean 100-episode return -1000.0
Finished with: 0

***
b'The mean 100-episode return after evaluation -1000.0\r\n'
*** Reward: -1000.0
Found optimal params [ 5.37260347 18.45860353]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.2686290418566744', '--epsilon=0.03', '--gamma=0.99']
[2018-11-19 14:52:26,931] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -1000.0
Episode 30, mean 100-episode return -962.0333333333333
Episode 40, mean 100-episode return -927.95
Episode 50, mean 100-episode return -869.94
Episode 60, mean 100-episode return -815.2
Episode 70, mean 100-episode return -800.5714285714286
Episode 80, mean 100-episode return -804.7625
Episode 90, mean 100-episode return -762.7
Episode 100, mean 100-episode return -767.24
Episode 110, mean 100-episode return -767.24
Episode 120, mean 100-episode return -767.24
Episode 130, mean 100-episode return -778.63
Episode 140, mean 100-episode return -796.06
Episode 150, mean 100-episode return -832.27
Episode 160, mean 100-episode return -878.12
Episode 170, mean 100-episode return -906.84
Episode 180, mean 100-episode return -923.43
Episode 190, mean 100-episode return -980.81
Episode 200, mean 100-episode return -1000.0
Finished with: 0

***
b'The mean 100-episode return after evaluation -1000.0\r\n'
*** Reward: -1000.0
Found optimal params [ 5.39390265 15.45496661]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=1.6003170431309155', '--epsilon=0.8', '--gamma=0.8']
[2018-11-19 14:52:32,709] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -1000.0
Episode 30, mean 100-episode return -1000.0
Episode 40, mean 100-episode return -1000.0
Episode 50, mean 100-episode return -1000.0
Episode 60, mean 100-episode return -1000.0
Episode 70, mean 100-episode return -1000.0
Episode 80, mean 100-episode return -1000.0
Episode 90, mean 100-episode return -1000.0
Episode 100, mean 100-episode return -1000.0
Episode 110, mean 100-episode return -998.27
Episode 120, mean 100-episode return -998.27
Episode 130, mean 100-episode return -998.27
Episode 140, mean 100-episode return -998.27
Episode 150, mean 100-episode return -998.27
Episode 160, mean 100-episode return -998.27
Episode 170, mean 100-episode return -998.27
Episode 180, mean 100-episode return -998.27
Episode 190, mean 100-episode return -998.27
Episode 200, mean 100-episode return -998.27
Finished with: 0

***
b'The mean 100-episode return after evaluation -1000.0\r\n'
*** Reward: -1000.0
Found optimal params [ 5.01341166 16.91361255]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=1.111880724777169', '--epsilon=0.03', '--gamma=0.8']
[2018-11-19 14:52:39,289] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -992.8
Episode 30, mean 100-episode return -939.8666666666667
Episode 40, mean 100-episode return -954.9
Episode 50, mean 100-episode return -963.92
Episode 60, mean 100-episode return -969.9333333333333
Episode 70, mean 100-episode return -974.2285714285714
Episode 80, mean 100-episode return -977.45
Episode 90, mean 100-episode return -979.9555555555555
Episode 100, mean 100-episode return -981.96
Episode 110, mean 100-episode return -981.96
Episode 120, mean 100-episode return -983.4
Episode 130, mean 100-episode return -1000.0
Episode 140, mean 100-episode return -1000.0
Episode 150, mean 100-episode return -1000.0
Episode 160, mean 100-episode return -1000.0
Episode 170, mean 100-episode return -1000.0
Episode 180, mean 100-episode return -1000.0
Episode 190, mean 100-episode return -1000.0
Episode 200, mean 100-episode return -1000.0
Finished with: 0

***
b'The mean 100-episode return after evaluation -1000.0\r\n'
*** Reward: -1000.0
Found optimal params [ 4.99217074 17.97094667]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.8477011737159392', '--epsilon=0.8', '--gamma=0.99']
[2018-11-19 14:52:45,715] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -1000.0
Episode 30, mean 100-episode return -999.6
Episode 40, mean 100-episode return -979.525
Episode 50, mean 100-episode return -972.58
Episode 60, mean 100-episode return -956.4
Episode 70, mean 100-episode return -940.6142857142858
Episode 80, mean 100-episode return -915.1625
Episode 90, mean 100-episode return -915.2333333333333
Episode 100, mean 100-episode return -905.56
Episode 110, mean 100-episode return -899.12
Episode 120, mean 100-episode return -892.51
Episode 130, mean 100-episode return -892.63
Episode 140, mean 100-episode return -900.7
Episode 150, mean 100-episode return -906.22
Episode 160, mean 100-episode return -912.23
Episode 170, mean 100-episode return -927.64
Episode 180, mean 100-episode return -953.94
Episode 190, mean 100-episode return -962.36
Episode 200, mean 100-episode return -980.51
Finished with: 0

***
b'The mean 100-episode return after evaluation -980.51\r\n'
*** Reward: -980.51
Found optimal params [ 4.83394748 20.73889697]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=1.0457598989432635', '--epsilon=0.43148511326335254', '--gamma=0.99']
[2018-11-19 14:52:51,744] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -1000.0
Episode 30, mean 100-episode return -1000.0
Episode 40, mean 100-episode return -1000.0
Episode 50, mean 100-episode return -990.56
Episode 60, mean 100-episode return -974.4
Episode 70, mean 100-episode return -966.6571428571428
Episode 80, mean 100-episode return -970.825
Episode 90, mean 100-episode return -967.4666666666667
Episode 100, mean 100-episode return -955.69
Episode 110, mean 100-episode return -955.69
Episode 120, mean 100-episode return -955.69
Episode 130, mean 100-episode return -955.69
Episode 140, mean 100-episode return -955.69
Episode 150, mean 100-episode return -960.41
Episode 160, mean 100-episode return -971.05
Episode 170, mean 100-episode return -979.03
Episode 180, mean 100-episode return -979.03
Episode 190, mean 100-episode return -984.97
Episode 200, mean 100-episode return -1000.0
Finished with: 0

***
b'The mean 100-episode return after evaluation -1000.0\r\n'
*** Reward: -1000.0
Found optimal params [ 2.17121387 10.4520674 ]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.6490364571390991', '--epsilon=0.6758483422110413', '--gamma=0.8']
[2018-11-19 14:52:58,112] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -1000.0
Episode 30, mean 100-episode return -978.4666666666667
Episode 40, mean 100-episode return -961.825
Episode 50, mean 100-episode return -944.26
Episode 60, mean 100-episode return -926.65
Episode 70, mean 100-episode return -916.2428571428571
Episode 80, mean 100-episode return -912.7
Episode 90, mean 100-episode return -882.7555555555556
Episode 100, mean 100-episode return -836.4
Episode 110, mean 100-episode return -760.95
Episode 120, mean 100-episode return -684.73
Episode 130, mean 100-episode return -614.45
Episode 140, mean 100-episode return -545.57
Episode 150, mean 100-episode return -479.97
Episode 160, mean 100-episode return -421.16
Episode 170, mean 100-episode return -361.13
Episode 180, mean 100-episode return -295.01
Episode 190, mean 100-episode return -254.41
Episode 200, mean 100-episode return -235.41
Finished with: 0

***
b'The mean 100-episode return after evaluation -235.21\r\n'
*** Reward: -235.21
Found optimal params [0.39813538 2.44065945]
Running: ['python', 'C:\\dev\\npfl122\\labs\\03\\q_learning.py', '--alpha=0.5282330887896225', '--epsilon=0.791632686166407', '--gamma=0.8']
[2018-11-19 14:53:02,345] Making new env: MountainCarLimit1000-v0
Episode 10, mean 100-episode return -1000.0
Episode 20, mean 100-episode return -1000.0
Episode 30, mean 100-episode return -981.8666666666667
Episode 40, mean 100-episode return -949.325
Episode 50, mean 100-episode return -915.56
Episode 60, mean 100-episode return -903.8333333333334
Episode 70, mean 100-episode return -863.3857142857142
Episode 80, mean 100-episode return -828.025
Episode 90, mean 100-episode return -799.1666666666666
Episode 100, mean 100-episode return -760.4
Episode 110, mean 100-episode return -755.93
Episode 120, mean 100-episode return -755.93
Episode 130, mean 100-episode return -761.37
Episode 140, mean 100-episode return -776.2
Episode 150, mean 100-episode return -798.15
Episode 160, mean 100-episode return -813.63
Episode 170, mean 100-episode return -851.56
Episode 180, mean 100-episode return -893.51
Episode 190, mean 100-episode return -936.68
Episode 200, mean 100-episode return -995.53
Finished with: 0

***
b'The mean 100-episode return after evaluation -1000.0\r\n'
*** Reward: -1000.0
max_x [0.64903646 0.67584834 0.8       ] max max -235.21




****************************
OptimizationResult(best_x=[0.64903646 0.67584834 0.8       ], best_y=-235.21)

Process finished with exit code 0
